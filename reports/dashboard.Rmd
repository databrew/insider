---
title: "INSIDER-facebook performance dashboard"
params:
  get_new_data: False
output: flexdashboard::flex_dashboard
---

```{r, echo = FALSE, warning = FALSE, message = FALSE, comment = NA, error= FALSE, cache = FALSE}

# If get_new_data is set to True,
# make sure that you are working within the "insider" virtualenv

# Libraries
library(tidyverse)
library(knitr)
library(highcharter)
library(Hmisc)
library(RColorBrewer)
library(plotly)
library(databrew)
library(ggmap)
library(rworldmap)

# Turn off scientific notation
options(scipen = '999')

# Custom functions
source('helpers.R')

# Basic knitr options
knitr::opts_chunk$set(comment = NA, 
               echo = FALSE, 
               warning = FALSE, 
               message = FALSE, 
               error = TRUE, # Render report, even with errors
               cache = F)

# Get new data if need be
if(params$get_new_data){
  owd <- getwd()
  setwd('../lib/')
  system('python get_data.py')
  setwd(owd)
}

# Read in the data
df <- read_csv('../data/historical.csv')

# Re-format the date
df$date <- as.Date(df$date)

# Get all locations
if('locations.csv' %in% dir()){
  locations <- read_csv('locations.csv')
} else {
  locations <- df %>%
    filter(key == "page_storytellers_by_city") %>%
    group_by(sub_key) %>%
    tally
  # Geocode
  gc <- ggmap::geocode(location = locations$sub_key,
                       output = c('latlon'))
  locations <- cbind(locations, gc) %>%
    dplyr::select(-n)
  # Save csv
  write_csv(locations, 'locations.csv')
}

# Join those locations to df
df <- left_join(x = df,
                y = locations,
                by = 'sub_key')
```


```{r}
# Ensure that only the most recent of each category is in the data
df <- 
  df %>%
  arrange(end_time) %>%
  group_by(key, name, date) %>%
  mutate(keep = end_time == max(end_time, na.rm = TRUE)) %>%
  ungroup %>%
  filter(keep) %>%
  dplyr::select(date, end_time, key, sub_key, name, value, lon, lat)

# Remove any duplicates
df <- 
  df %>%
  arrange(end_time) %>%
  group_by(key, sub_key, name, date) %>%
  mutate(n = n()) %>%
  filter(n == 1) %>%
  ungroup %>%
  dplyr::select(-n)

# Keep only values after a certain date
starter <- min(df$date[df$value > 0], na.rm = TRUE)
df <- df %>%
  filter(date >= starter)

# Clean up names
df$x <- gsub('thisis|insider', '', tolower(df$name))
df$name <- ifelse(df$name != 'thisisinsider', df$x, df$name)
df$name[df$name == 'thisisinsder'] <- 'This Is Insider'
df$name <- Hmisc::capitalize(df$name)
df$x <- NULL

# Get a cumulative count
df <- 
  df %>%
  arrange(date) %>%
  group_by(key, sub_key, name) %>%
  mutate(value_cum = cum_summer(value))
```


Yesterday
=====================================  
    
   
Column {.tabset}
-------------------------------------
   

### Yesterday's views

```{r}
# this is for most recent day
x <- 
  df %>%
  filter(!is.na(value)) %>%
  group_by(name, key) %>%
  filter(date == max(date)) %>%
  group_by(name) %>%
  summarise(page_views = dplyr::first(value[key == 'page_views']),
            fan_adds = dplyr::first(value[key == 'page_fan_adds'])) %>%
  ungroup

p <- ggplot(x, aes(name, page_views)) + 
     geom_bar(stat = 'identity', fill = 'darkorange', colour = 'blue', alpha = 0.7) + 
     ggtitle("Yesterday's views by channel") + 
     theme_databrew() + theme(axis.text.x = element_text(angle = 45, hjust=1)) 

p
```

### Yesterday's likes

```{r}
p <- ggplot(x, aes(name, fan_adds)) + 
  geom_bar(stat = 'identity', fill = 'darkorange', colour = 'blue', alpha = 0.7) + 
  ggtitle("Yesterday's likes by channel") + 
  theme_databrew() + theme(axis.text.x = element_text(angle = 45, hjust=1)) 

p
```
   

Column {.tabset}
-------------------------------------
   

### Yesterday's views to fan adds correlation

The correlation between views (x-axis) and fan adds (y-axis) is one indicator of how people interact with Insider on different facebook pages. The (blue) line of best fit shows the general associaton between the two metrics. Those points above the line get more fan adds than their view counts would suggest (ie, passionate fans); those below the line get more counts but fewer than expected fan adds (ie, passer-bys). 
    
```{r}
x <- 
  df %>%
  filter(!is.na(value)) %>%
  group_by(name, key) %>%
  filter(date == max(date)) %>%
  group_by(name) %>%
  summarise(page_views = sum(value[key == 'page_views']),
            page_fan_adds = sum(value[key == 'page_fan_adds'])) %>%
  ungroup

g <- ggplot(data = x,
       aes(x = page_views,
           y = page_fan_adds,
           label = name)) +
  geom_point(alpha = 0.6,
             color = 'darkorange',
             size = 4) +
  labs(x = 'Page views',
       y = 'Fan adds',
        title = "Yesterday's",
       subtitle = 'Likes vs Views') +
  theme_databrew() +
  geom_smooth(method = 'lm', se = FALSE)
ggplotly(g, tootip = 'name')
```

### Avg views to fan adds correlation

The correlation between views (x-axis) and fan adds (y-axis) is one indicator of how people interact with Insider on different facebook pages. The (blue) line of best fit shows the general associaton between the two metrics. Those points above the line get more fan adds than their view counts would suggest (ie, passionate fans); those below the line get more counts but fewer than expected fan adds (ie, passer-bys). 
    
```{r}
x_2017 <- 
  df %>%
  filter(!is.na(value)) %>%
  group_by(name, key) %>%
  filter(date != max(date)) %>%
  filter(date  > '2016-12-31') %>%
  group_by(name) %>%
  summarise(page_views = round(mean(value[key == 'page_views']), 2),
            page_fan_adds = round(mean(value[key == 'page_fan_adds']), 2)) %>%
  ungroup

g <- ggplot(data = x_2017,
       aes(x = page_views,
           y = page_fan_adds,
           label = name)) +
  geom_point(alpha = 0.6,
             color = 'darkorange',
             size = 4) +
  labs(x = 'Page views',
       y = 'Fan adds',
       title = '2017 Avg',
       subtitle = 'Likes vs Views') +
  theme_databrew() +
  geom_smooth(method = 'lm', se = FALSE)
ggplotly(g, tootip = 'name')
```

Cumulative
=====================================  
    
   
Column {.tabset}
-------------------------------------
   
   
### Cumulative fan adds 

```{r}
time_chart(the_key = 'page_fan_adds') +
  theme_databrew()
```   

    
### Cumulative page views
    
```{r}
time_chart(the_key = 'page_views') +
  theme_databrew()
```

 
   
Column {.tabset}
-------------------------------------

### views and fan adds over time

```{r}
x <- df %>%
  ungroup %>%
  filter(key %in% c('page_fan_adds', 'page_views')) %>%
  mutate(key = ifelse(key == 'page_fan_adds', 'Fan adds', 'Page views')) %>%
  group_by(date, key) %>%
  summarise(n = sum(value_cum))
cols <- c('blue', 'darkorange')

ggplot(data = x,
       aes(x = date,
           y = n)) +
  geom_line(aes(color = key),
            alpha = 0.6,
            size = 1.5) +
  theme_databrew() +
  labs(x = 'Date',
       y = 'Value',
       title = 'All 16 pages') +
  scale_color_manual(name = '',
                     values = cols)
```


Data {data-orientation=rows}
=====================================     
   
Row {data-height=300}
-------------------------------------

### Data repository

Soon a link to a stable repository for data (google docs, for example) will be placed here.

Row {data-height=700}
-------------------------------------
   
### Data explorer

```{r}
# filtering down so that it's not too much data / too slow
DT::datatable(df[1:1000,] %>%
                dplyr::select(date, key, sub_key, name, value, value_cum))
```   
    


Insights
=====================================  
    
Column {.tabset}
-------------------------------------

### Positive and Negative Feedback

Postive feedback is... 
Negative feedback is defined ...

```{r}
 x <- 
    df %>%
    filter(!is.na(value)) %>%
    group_by(name, key) %>%
    filter(date  > '2016-12-31') %>%
    group_by(name) %>%
    summarise(num_pos = round(mean(value[key == 'page_positive_feedback_by_type']), 2),
              num_neg = round(mean(value[key == 'page_negative_feedback']), 2)) %>%
    ungroup




```   


### Storytellers by gender

```{r}

# get data for sub key analysis
x_2017 <- 
    df %>%
    filter(!is.na(value)) %>%
    group_by(name, key, sub_key) %>%
    filter(date  > '2016-12-31') %>%
    group_by(name, key, sub_key) %>%
    summarise(counts = n())



```  
    
   
Column {.tabset}
-------------------------------------
   

### By city

```{r}
library(rworldmap)
world <- map_data(map="world")
cities <- df %>%
  filter(key == 'page_storytellers_by_city') %>%
  group_by(sub_key, lon, lat) %>%
  summarise(value = sum(value, na.rm = TRUE))
ggplot() +
  geom_polygon(data = world, aes(x = long, y = lat,
                                 group = group)) +
  geom_point(data = cities,
             aes(x = lon,
                 y = lat,
                 size = value),
             col = 'red',
             alpha = 0.2) +
  theme_databrew() +
  theme(legend.position="none") +
  labs(x = '', y = '')
```

### By country

```{r}
barplot(1:10)
```